import React, { useState, useRef, useEffect } from 'react'
import './App.css'

export default function ChatBox() {
  const [messages, setMessages] = useState([])
  const [input, setInput] = useState('')
  const [listening, setListening] = useState(false)
  const recognitionRef = useRef(null)
  const messagesEndRef = useRef(null)

  // Backend base URL t·ª´ Vite env: VITE_API_URL
  const API_BASE = import.meta.env.VITE_API_URL || 'http://127.0.0.1:5000'
  const CHAT_URL = `${API_BASE.replace(/\/$/, '')}/chat`

  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' })
  }, [messages])

  // Kh·ªüi t·∫°o SpeechRecognition
  useEffect(() => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    if (!SpeechRecognition) {
      console.warn('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ Web Speech API')
      return
    }
    const rec = new SpeechRecognition()
    rec.lang = 'vi-VN'
    rec.continuous = false
    rec.interimResults = false

    rec.onresult = (e) => {
      const text = e.results[0][0].transcript
      handleSend(text, true)
    }
    rec.onend = () => setListening(false)
    rec.onerror = (err) => {
      console.error('SpeechRecognition error', err)
      setListening(false)
    }
    recognitionRef.current = rec
  }, [])

  const handleSend = async (text, fromVoice = false) => {
    if (!text || !text.trim()) return
    setMessages(prev => [...prev, { sender: 'B·∫°n', text }])
    if (!fromVoice) setInput('')

    // G·ªçi backend
    try {
      const res = await fetch(CHAT_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message: text })
      })
      const data = await res.json()
      const reply = data.reply || `ThamAI (gi·∫£ l·∫≠p) nh·∫≠n: ${text}`
      setMessages(prev => [...prev, { sender: 'ThamAI', text: reply }])

      // TTS
      if ('speechSynthesis' in window) {
        const u = new SpeechSynthesisUtterance(reply)
        u.lang = 'vi-VN'
        window.speechSynthesis.speak(u)
      }
    } catch (err) {
      console.error('L·ªói g·ªçi backend', err)
      const fallback = `ThamAI (offline) ƒë√£ nh·∫≠n: ${text}`
      setMessages(prev => [...prev, { sender: 'ThamAI', text: fallback }])
    }
  }

  const startListening = () => {
    if (!recognitionRef.current) {
      alert('Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ nh·∫≠n di·ªán gi·ªçng n√≥i')
      return
    }
    setListening(true)
    recognitionRef.current.start()
  }

  return (
    <div className="chatbox-wrapper">
      <div className="chatbox">
        <div className="messages">
          {messages.map((m, i) => (
            <div key={i} className={m.sender === 'B·∫°n' ? 'msg user' : 'msg bot'}>
              <strong>{m.sender}:</strong> {m.text}
            </div>
          ))}
          <div ref={messagesEndRef} />
        </div>
        <div className="controls">
          <input
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={(e) => e.key === 'Enter' && handleSend(input)}
            placeholder="Nh·∫≠p tin nh·∫Øn..."
          />
          <button onClick={() => handleSend(input)}>G·ª≠i</button>
          <button className={listening ? 'mic active' : 'mic'} onClick={startListening}>üé§</button>
        </div>
      </div>
    </div>
  )
}
